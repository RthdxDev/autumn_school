{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:21.416401Z",
     "iopub.status.busy": "2025-11-21T15:42:21.416105Z",
     "iopub.status.idle": "2025-11-21T15:42:25.780254Z",
     "shell.execute_reply": "2025-11-21T15:42:25.779493Z",
     "shell.execute_reply.started": "2025-11-21T15:42:21.416379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poetry dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/matta/repos/autumn_school/data/russianPoetryWithTheme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['author', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Михаил Лермонтов</td>\n",
       "      <td>Забывши волнения жизни мятежной,\\r\\nОдин жил в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Сергей Есенин</td>\n",
       "      <td>Нивы сжаты, рощи голы,\\r\\nОт воды туман и сыро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Игорь Северянин</td>\n",
       "      <td>Лючинь печальная читала вечером ручьисто-вкрад...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Анатолий Жигулин</td>\n",
       "      <td>Глыбу кварца разбили молотом,\\r\\nИ, веселым ог...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Николай Тихонов</td>\n",
       "      <td>Хлынул дождь, когда девушки, встав в хоровод,\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16689</th>\n",
       "      <td>Леонид Мартынов</td>\n",
       "      <td>Седо\\r\\nКурчавятся облака\\r\\nНад чернотою поле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16690</th>\n",
       "      <td>Гаврила Державин</td>\n",
       "      <td>Белокурая Параша,\\r\\nСребророзова лицом,\\r\\nКо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16691</th>\n",
       "      <td>Федор Сологуб</td>\n",
       "      <td>Сладкозвучная богиня,\\r\\nРифма золотая,\\r\\nСлу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16692</th>\n",
       "      <td>Илья Эренбург</td>\n",
       "      <td>Я так любил тебя — до грубых шуток\\r\\nИ до так...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16693</th>\n",
       "      <td>Геннадий Шпаликов</td>\n",
       "      <td>С. А. Швейцер\\r\\nс нежностью и уважением\\r\\nГ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16694 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author                                               text\n",
       "0       Михаил Лермонтов  Забывши волнения жизни мятежной,\\r\\nОдин жил в...\n",
       "1          Сергей Есенин  Нивы сжаты, рощи голы,\\r\\nОт воды туман и сыро...\n",
       "2        Игорь Северянин  Лючинь печальная читала вечером ручьисто-вкрад...\n",
       "3       Анатолий Жигулин  Глыбу кварца разбили молотом,\\r\\nИ, веселым ог...\n",
       "4        Николай Тихонов  Хлынул дождь, когда девушки, встав в хоровод,\\...\n",
       "...                  ...                                                ...\n",
       "16689    Леонид Мартынов  Седо\\r\\nКурчавятся облака\\r\\nНад чернотою поле...\n",
       "16690   Гаврила Державин  Белокурая Параша,\\r\\nСребророзова лицом,\\r\\nКо...\n",
       "16691      Федор Сологуб  Сладкозвучная богиня,\\r\\nРифма золотая,\\r\\nСлу...\n",
       "16692      Илья Эренбург  Я так любил тебя — до грубых шуток\\r\\nИ до так...\n",
       "16693  Геннадий Шпаликов  С. А. Швейцер\\r\\nс нежностью и уважением\\r\\nГ....\n",
       "\n",
       "[16694 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ''.join(chr(i) for i in range(ord('а'), ord('я') + 1))\n",
    "alphabet += ' \\n.,!?-«»()—…:;\\\"\\''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower().apply(lambda x: '<start> ' + ''.join([ch for ch in x if ch in alphabet]) + ' <end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVr9EW7_Z7k2"
   },
   "outputs": [],
   "source": [
    "chars = sorted(set(list(''.join(df['text'].to_list()))))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i,ch in enumerate(chars)} # string to index\n",
    "itos = {i: ch for i,ch in enumerate(chars)} # index to string\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:32.488435Z",
     "iopub.status.busy": "2025-11-21T15:42:32.487694Z",
     "iopub.status.idle": "2025-11-21T15:42:32.494521Z",
     "shell.execute_reply": "2025-11-21T15:42:32.493735Z",
     "shell.execute_reply.started": "2025-11-21T15:42:32.488408Z"
    },
    "id": "wfTBsxYCaRPD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\t\"\"\"\n",
    "\tOne head of self-attention\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, emb_size, head_size, dropout=0.0):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.head_size = head_size\n",
    "\t\tself.query = nn.Linear(emb_size, head_size, bias=False)\n",
    "\t\tself.key = nn.Linear(emb_size, head_size, bias=False)\n",
    "\t\tself.value = nn.Linear(emb_size, head_size, bias=False)\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\tself.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tQ = self.query(x)\n",
    "\t\tK = self.key(x)\n",
    "\t\tV = self.value(x)\n",
    "\t\tattention_score = Q @ K.transpose(-2, -1) / (self.head_size ** 0.5)\n",
    "\n",
    "\t\t# if self.training:\n",
    "\t\t# \tmask = torch.tril(torch.ones(seq_len, seq_len)).to(device)\n",
    "\t\t# \tattention_score = attention_score.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "\t\tout = self.softmax(attention_score) @ V\n",
    "\t\tout = self.dropout(out)\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:32.654553Z",
     "iopub.status.busy": "2025-11-21T15:42:32.654313Z",
     "iopub.status.idle": "2025-11-21T15:42:32.659754Z",
     "shell.execute_reply": "2025-11-21T15:42:32.659201Z",
     "shell.execute_reply.started": "2025-11-21T15:42:32.654535Z"
    },
    "id": "G4fSujOMbToB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\t\"\"\"\n",
    "\tMultiple heads of self-attention in parallel\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, emb_size, num_heads, head_size, dropout=0.0):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.heads = nn.ModuleList(\n",
    "\t\t\t[\n",
    "\t\t\t\tHead(emb_size=emb_size, head_size=head_size, dropout=dropout)\n",
    "\t\t\t\tfor _ in range(num_heads)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t\tself.linear = nn.Linear(num_heads * head_size, emb_size)\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tout = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "\t\tout = self.linear(out)\n",
    "\t\tout = self.dropout(out)\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:32.810311Z",
     "iopub.status.busy": "2025-11-21T15:42:32.809582Z",
     "iopub.status.idle": "2025-11-21T15:42:32.814820Z",
     "shell.execute_reply": "2025-11-21T15:42:32.814105Z",
     "shell.execute_reply.started": "2025-11-21T15:42:32.810291Z"
    },
    "id": "lncNKuNGby54",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "\t\"\"\"\n",
    "\tA simple linear layer followed by a non-linearity\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, emb_size, hidden_size, dropout=0.0):\t\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.linear1 = nn.Linear(emb_size, hidden_size)\n",
    "\t\tself.linear2 = nn.Linear(hidden_size, emb_size)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.linear1(x)\n",
    "\t\tx = self.relu(x)\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = self.linear2(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:32.946017Z",
     "iopub.status.busy": "2025-11-21T15:42:32.945842Z",
     "iopub.status.idle": "2025-11-21T15:42:32.950373Z",
     "shell.execute_reply": "2025-11-21T15:42:32.949802Z",
     "shell.execute_reply.started": "2025-11-21T15:42:32.946003Z"
    },
    "id": "Kjp9ECkkb6k1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\t\"\"\"\n",
    "\tTransformer block: communication followed by computation\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, emb_size, num_heads, head_size, hidden_size, dropout=0.0):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.attention = MultiHeadAttention(emb_size, num_heads, head_size, dropout)\n",
    "\t\tself.ffn = FeedForwardNetwork(emb_size, hidden_size, dropout)\n",
    "\t\tself.norm1 = nn.LayerNorm(emb_size)\n",
    "\t\tself.norm2 = nn.LayerNorm(emb_size)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.norm1(x + self.attention(x))\n",
    "\t\tx = self.norm2(x + self.ffn(x))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:33.072383Z",
     "iopub.status.busy": "2025-11-21T15:42:33.071753Z",
     "iopub.status.idle": "2025-11-21T15:42:33.078940Z",
     "shell.execute_reply": "2025-11-21T15:42:33.078307Z",
     "shell.execute_reply.started": "2025-11-21T15:42:33.072360Z"
    },
    "id": "hRk1z3Wncjmw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "\tdef __init__(self, dict_size, emb_size, seq_len, num_heads=8, head_size=64, hidden_size=2048, dropout=0.3):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.token_embedding_table = nn.Embedding(num_embeddings=dict_size, embedding_dim=emb_size)\n",
    "\t\tself.blocks = nn.Sequential(\n",
    "\t\t\t*[\n",
    "\t\t\t\tTransformerBlock(\n",
    "\t\t\t\temb_size=emb_size,\n",
    "\t\t   \t\tnum_heads=num_heads,\n",
    "\t\t\t\thead_size=head_size,\n",
    "\t\t\t\thidden_size=hidden_size,\n",
    "\t\t\t\tdropout=dropout\n",
    "\t\t\t\t) for _ in range(6)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.linear = nn.Linear(emb_size * seq_len, dict_size)\n",
    "\t\tself.apply(self._init_weights)\n",
    "\n",
    "\tdef _init_weights(self, module):\n",
    "\t\tif isinstance(module, nn.Linear):\n",
    "\t\t\ttorch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\t\t\tif module.bias is not None:\n",
    "\t\t\t\ttorch.nn.init.zeros_(module.bias)\n",
    "\t\telif isinstance(module, nn.Embedding):\n",
    "\t\t\ttorch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\tdef forward(self, idx):\n",
    "\t\t# idx = torch.argmax(x, dim=-1)\n",
    "\t\temb = self.token_embedding_table(idx)\n",
    "\t\tout = self.blocks(emb)\n",
    "\t\tout = self.flatten(out)\n",
    "\t\tlogits = self.linear(out)\n",
    "\t\treturn logits\n",
    "\n",
    "\tdef generate_next_token(self, idx):\n",
    "\t\tlogits = self.forward(idx)\n",
    "\t\tprobs = F.softmax(logits, dim=-1)\n",
    "\t\tnext_token = torch.multinomial(probs, num_samples=1)\n",
    "\t\treturn next_token\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:35.352128Z",
     "iopub.status.busy": "2025-11-21T15:42:35.351526Z",
     "iopub.status.idle": "2025-11-21T15:42:35.368264Z",
     "shell.execute_reply": "2025-11-21T15:42:35.367674Z",
     "shell.execute_reply.started": "2025-11-21T15:42:35.352093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f = open('/home/matta/repos/autumn_school/data/names.txt', 'r')\n",
    "names = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:35.679915Z",
     "iopub.status.busy": "2025-11-21T15:42:35.679305Z",
     "iopub.status.idle": "2025-11-21T15:42:35.687745Z",
     "shell.execute_reply": "2025-11-21T15:42:35.687016Z",
     "shell.execute_reply.started": "2025-11-21T15:42:35.679893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NamesDataset(Dataset):\n",
    "\tdef __init__(self, names: list[str], seq_len: int=3):\n",
    "\t\tself._seq_len = seq_len\n",
    "\t\tself.__stoi = {\n",
    "\t\t\t\"<start>\": 0,\n",
    "\t\t\t\"<end>\": 1,\n",
    "\t\t}\n",
    "\t\tfor i, ch in enumerate(sorted(set(''.join(names)))):\n",
    "\t\t\tself.__stoi[ch] = i + 2\n",
    "\t\tself.__itos = {i: ch for ch, i in self.__stoi.items()}\n",
    "\t\tself.names: list[tuple[str, str]] = []\n",
    "\t\tself.names_encoded: list[tuple[Tensor, Tensor]] = []\n",
    "\t\tfor name in names:\n",
    "\t\t\tname_lst = list(name) + ['<end>']\n",
    "\t\t\tfor i in range(len(name_lst)):\n",
    "\t\t\t\ttarget: str = name_lst[i]\n",
    "\t\t\t\ttarget_encoded = torch.tensor([self.__stoi[target]])\n",
    "\t\t\t\tpart_name = name_lst[max(0, i - self.seq_len):i]\n",
    "\t\t\t\tentry = [\"<start>\"] * (self.seq_len - len(part_name)) + part_name\n",
    "\t\t\t\tentry_encoded = torch.tensor([self.__stoi[\"<start>\"]] * (self.seq_len - len(part_name)) + [self.__stoi[ch] for ch in part_name])\n",
    "\t\t\t\tself.names.append((entry, target))\n",
    "\t\t\t\tself.names_encoded.append((entry_encoded, target_encoded))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.names)\n",
    "\t\n",
    "\t@property\n",
    "\tdef seq_len(self):\n",
    "\t\treturn self._seq_len\n",
    "\t\n",
    "\t@property\n",
    "\tdef stoi(self):\n",
    "\t\treturn self.__stoi\n",
    "\t\n",
    "\t@property\t\n",
    "\tdef itos(self):\n",
    "\t\treturn self.__itos\n",
    "\t\n",
    "\tdef get_sample(self, idx):\n",
    "\t\treturn self.names[idx]\n",
    "\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\treturn self.names_encoded[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:37.462644Z",
     "iopub.status.busy": "2025-11-21T15:42:37.461952Z",
     "iopub.status.idle": "2025-11-21T15:42:41.237001Z",
     "shell.execute_reply": "2025-11-21T15:42:41.236156Z",
     "shell.execute_reply.started": "2025-11-21T15:42:37.462618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "names_dataset = NamesDataset(names)\n",
    "names_loader = DataLoader(names_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:42:41.238668Z",
     "iopub.status.busy": "2025-11-21T15:42:41.238285Z",
     "iopub.status.idle": "2025-11-21T15:42:41.242757Z",
     "shell.execute_reply": "2025-11-21T15:42:41.242120Z",
     "shell.execute_reply.started": "2025-11-21T15:42:41.238639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['<start>', '<start>', '<start>'], 'e')\n",
      "(['<start>', '<start>', 'e'], 'm')\n",
      "(['<start>', 'e', 'm'], 'm')\n",
      "(['e', 'm', 'm'], 'a')\n",
      "(['m', 'm', 'a'], '<end>')\n",
      "(['<start>', '<start>', '<start>'], 'o')\n",
      "(['<start>', '<start>', 'o'], 'l')\n",
      "(['<start>', 'o', 'l'], 'i')\n",
      "(['o', 'l', 'i'], 'v')\n",
      "(['l', 'i', 'v'], 'i')\n",
      "(['i', 'v', 'i'], 'a')\n",
      "(['v', 'i', 'a'], '<end>')\n",
      "(['<start>', '<start>', '<start>'], 'a')\n",
      "(['<start>', '<start>', 'a'], 'v')\n",
      "(['<start>', 'a', 'v'], 'a')\n",
      "(['a', 'v', 'a'], '<end>')\n",
      "(['<start>', '<start>', '<start>'], 'i')\n",
      "(['<start>', '<start>', 'i'], 's')\n",
      "(['<start>', 'i', 's'], 'a')\n",
      "(['i', 's', 'a'], 'b')\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(names_dataset.get_sample(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T15:44:14.744813Z",
     "iopub.status.busy": "2025-11-21T15:44:14.744147Z",
     "iopub.status.idle": "2025-11-21T15:44:14.772679Z",
     "shell.execute_reply": "2025-11-21T15:44:14.772141Z",
     "shell.execute_reply.started": "2025-11-21T15:44:14.744790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = GPT(\n",
    "\tdict_size=len(names_dataset.stoi),\n",
    "\temb_size=8, seq_len=names_dataset.seq_len,\n",
    "\thidden_size=64, num_heads=8,\n",
    "\thead_size=64,\n",
    "\tdropout=0.3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:07:56.562330Z",
     "iopub.status.busy": "2025-11-21T18:07:56.561719Z",
     "iopub.status.idle": "2025-11-21T18:07:56.568365Z",
     "shell.execute_reply": "2025-11-21T18:07:56.567822Z",
     "shell.execute_reply.started": "2025-11-21T18:07:56.562303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:07:59.890316Z",
     "iopub.status.busy": "2025-11-21T18:07:59.890056Z",
     "iopub.status.idle": "2025-11-21T18:07:59.893886Z",
     "shell.execute_reply": "2025-11-21T18:07:59.893292Z",
     "shell.execute_reply.started": "2025-11-21T18:07:59.890296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:08:01.592526Z",
     "iopub.status.busy": "2025-11-21T18:08:01.592255Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:28<00:00, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 20, Loss: 2.3163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:28<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 20, Loss: 2.3057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:28<00:00, 21.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 20, Loss: 2.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:30<00:00, 21.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 20, Loss: 2.2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:32<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 20, Loss: 2.2882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:27<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 20, Loss: 2.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:27<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 20, Loss: 2.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:27<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 20, Loss: 2.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:28<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 20, Loss: 2.2746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:27<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 / 20, Loss: 2.2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:26<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 / 20, Loss: 2.2716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:25<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 20, Loss: 2.2718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:25<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 / 20, Loss: 2.2696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7130/7130 [05:26<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 / 20, Loss: 2.2696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 4577/7130 [03:28<01:55, 22.06it/s]"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "for epoch in range(epochs):\n",
    "\tmodel.train()\n",
    "\ttotal_loss = 0\n",
    "\tfor seq, target in tqdm(names_loader):\n",
    "\t\tseq, target = seq.to(device), target.to(device)\n",
    "\t\ttarget = F.one_hot(target, num_classes=len(names_dataset.stoi)).squeeze(1).float()\n",
    "\t\toptim.zero_grad()\n",
    "\t\tlogits = model(seq)\n",
    "\t\tloss = criterion(logits, target)\n",
    "\t\tloss.backward()\n",
    "\t\toptim.step()\n",
    "\t\ttotal_loss += loss.item()\n",
    "\tavg_loss = total_loss / len(names_loader)\n",
    "\tloss_history.append(avg_loss)\n",
    "\tprint(f\"Epoch {epoch + 1} / {epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T20:05:24.385404Z",
     "iopub.status.busy": "2025-11-21T20:05:24.384644Z",
     "iopub.status.idle": "2025-11-21T20:05:24.407789Z",
     "shell.execute_reply": "2025-11-21T20:05:24.407081Z",
     "shell.execute_reply.started": "2025-11-21T20:05:24.385380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/gpt-name-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('/home/matta/repos/autumn_school/gpt-name-3', weights_only=True, map_location=device)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T20:03:28.698520Z",
     "iopub.status.busy": "2025-11-21T20:03:28.698010Z",
     "iopub.status.idle": "2025-11-21T20:03:28.703425Z",
     "shell.execute_reply": "2025-11-21T20:03:28.702724Z",
     "shell.execute_reply.started": "2025-11-21T20:03:28.698470Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_name(model):\n",
    "    itos = names_dataset.itos\n",
    "    seq = torch.zeros(names_dataset.seq_len).reshape(1, 3).to(device).int()\n",
    "    end_token = names_dataset.stoi['<end>']\n",
    "    name = []\n",
    "    while True:\n",
    "        next_token = model.generate_next_token(seq)\n",
    "        if next_token.item() == end_token:\n",
    "            break\n",
    "        name.append(itos[next_token.item()])\n",
    "        seq = torch.cat([seq, next_token], dim=1)[:, 1:]\n",
    "    return ''.join(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T20:05:10.364901Z",
     "iopub.status.busy": "2025-11-21T20:05:10.364659Z",
     "iopub.status.idle": "2025-11-21T20:05:11.349328Z",
     "shell.execute_reply": "2025-11-21T20:05:11.348634Z",
     "shell.execute_reply.started": "2025-11-21T20:05:10.364884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keryab\n",
      "ilder\n",
      "samen\n",
      "hirbelranna\n",
      "aliea\n",
      "kere\n",
      "aster\n",
      "jenn\n",
      "jaan\n",
      "pena\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_name(model))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8781902,
     "sourceId": 13793849,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
